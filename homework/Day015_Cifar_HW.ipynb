{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder(categories='auto')\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "#'自己設計參數' eg:32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu')) #'自己設計參數'\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "#'自己設計FC層參數'\n",
    "classifier.add(Dense(output_dim=100, activation='relu', kernel_regularizer=regularizers.l2(l=0.001))) #output_dim=100,activation=relu\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(p=0.5)) #Dropout\n",
    "\n",
    "classifier.add(Dense(output_dim=100, activation='relu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(p=0.3))\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10, activation='softmax')) #'輸出函數應該用什麼？'\n",
    "\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator #Augmentation\n",
    "img_gen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, rotation_range=10,\n",
    "                            width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1,\n",
    "                            zoom_range=0.1, horizontal_flip=True, vertical_flip=False, dtype=np.float32)\n",
    "img_gen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 2.1226 - acc: 0.3461 - val_loss: 1.5928 - val_acc: 0.5115\n",
      "Epoch 2/100\n",
      "  9/500 [..............................] - ETA: 7s - loss: 1.8386 - acc: 0.4289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `test_loss` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 21s 43ms/step - loss: 1.6753 - acc: 0.4749 - val_loss: 1.3894 - val_acc: 0.5663\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 1.4847 - acc: 0.5371 - val_loss: 1.3085 - val_acc: 0.5912\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.3782 - acc: 0.5690 - val_loss: 1.1726 - val_acc: 0.6443\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.3040 - acc: 0.5913 - val_loss: 1.1290 - val_acc: 0.6564\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.2549 - acc: 0.6044 - val_loss: 1.0953 - val_acc: 0.6607\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 1.2226 - acc: 0.6131 - val_loss: 1.1011 - val_acc: 0.6571\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.1989 - acc: 0.6252 - val_loss: 1.1845 - val_acc: 0.6375\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1785 - acc: 0.6309 - val_loss: 1.0153 - val_acc: 0.6865\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1631 - acc: 0.6348 - val_loss: 1.0199 - val_acc: 0.6874\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1485 - acc: 0.6417 - val_loss: 1.1037 - val_acc: 0.6583\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1335 - acc: 0.6468 - val_loss: 1.1243 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1275 - acc: 0.6513 - val_loss: 0.9904 - val_acc: 0.6974\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.1190 - acc: 0.6544 - val_loss: 1.1248 - val_acc: 0.6497\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1172 - acc: 0.6540 - val_loss: 1.0814 - val_acc: 0.6714\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0990 - acc: 0.6609 - val_loss: 1.0036 - val_acc: 0.6944\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.1018 - acc: 0.6635 - val_loss: 0.9907 - val_acc: 0.6945\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0900 - acc: 0.6663 - val_loss: 1.0004 - val_acc: 0.6954\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0806 - acc: 0.6697 - val_loss: 0.9934 - val_acc: 0.6989\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 1.0864 - acc: 0.6663 - val_loss: 0.9830 - val_acc: 0.7050\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0761 - acc: 0.6704 - val_loss: 1.0193 - val_acc: 0.6929\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 1.0701 - acc: 0.6737 - val_loss: 1.0460 - val_acc: 0.6866\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 1.0695 - acc: 0.6750 - val_loss: 1.0158 - val_acc: 0.6964\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0638 - acc: 0.6765 - val_loss: 0.9831 - val_acc: 0.6982\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0580 - acc: 0.6807 - val_loss: 1.0304 - val_acc: 0.6905\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0533 - acc: 0.6803 - val_loss: 1.1636 - val_acc: 0.6522\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0513 - acc: 0.6807 - val_loss: 0.9263 - val_acc: 0.7183\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0566 - acc: 0.6795 - val_loss: 0.9522 - val_acc: 0.7082\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0433 - acc: 0.6822 - val_loss: 0.9426 - val_acc: 0.7147\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0429 - acc: 0.6835 - val_loss: 1.0998 - val_acc: 0.6698\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0447 - acc: 0.6819 - val_loss: 0.9917 - val_acc: 0.7071\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0276 - acc: 0.6885 - val_loss: 0.9743 - val_acc: 0.7057\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0387 - acc: 0.6883 - val_loss: 0.9856 - val_acc: 0.7041\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0247 - acc: 0.6901 - val_loss: 0.9670 - val_acc: 0.7126\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0305 - acc: 0.6875 - val_loss: 0.9588 - val_acc: 0.7104\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0269 - acc: 0.6896 - val_loss: 0.8893 - val_acc: 0.7344\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0240 - acc: 0.6923 - val_loss: 0.9967 - val_acc: 0.7005\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0154 - acc: 0.6924 - val_loss: 0.9218 - val_acc: 0.7249\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0176 - acc: 0.6946 - val_loss: 0.9406 - val_acc: 0.7176\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0169 - acc: 0.6927 - val_loss: 0.9077 - val_acc: 0.7272\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0108 - acc: 0.6957 - val_loss: 0.9068 - val_acc: 0.7274\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0077 - acc: 0.6953 - val_loss: 0.9519 - val_acc: 0.7141\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0046 - acc: 0.6973 - val_loss: 0.9444 - val_acc: 0.7180\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0082 - acc: 0.6962 - val_loss: 0.9773 - val_acc: 0.7065\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0090 - acc: 0.6955 - val_loss: 0.9978 - val_acc: 0.6994\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0097 - acc: 0.6949 - val_loss: 0.8776 - val_acc: 0.7381\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 1.0023 - acc: 0.6960 - val_loss: 0.9811 - val_acc: 0.7035\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 1.0032 - acc: 0.6994 - val_loss: 0.8855 - val_acc: 0.7307\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9984 - acc: 0.7008 - val_loss: 0.9515 - val_acc: 0.7194\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9993 - acc: 0.6997 - val_loss: 0.9622 - val_acc: 0.7153\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9990 - acc: 0.6980 - val_loss: 0.9281 - val_acc: 0.7225\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9938 - acc: 0.7023 - val_loss: 0.9432 - val_acc: 0.7186\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9961 - acc: 0.7004 - val_loss: 0.9536 - val_acc: 0.7103\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9899 - acc: 0.7020 - val_loss: 0.8792 - val_acc: 0.7398\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9942 - acc: 0.7010 - val_loss: 0.9163 - val_acc: 0.7253\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9907 - acc: 0.7037 - val_loss: 0.8959 - val_acc: 0.7306\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9912 - acc: 0.7017 - val_loss: 1.0175 - val_acc: 0.6988\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9903 - acc: 0.7035 - val_loss: 0.9886 - val_acc: 0.7037\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9887 - acc: 0.7022 - val_loss: 0.9409 - val_acc: 0.7165\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9912 - acc: 0.7003 - val_loss: 1.0008 - val_acc: 0.7056\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9904 - acc: 0.7020 - val_loss: 0.9336 - val_acc: 0.7187\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9857 - acc: 0.7032 - val_loss: 0.9242 - val_acc: 0.7265\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9842 - acc: 0.7049 - val_loss: 0.9689 - val_acc: 0.7119\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9772 - acc: 0.7061 - val_loss: 0.9375 - val_acc: 0.7186\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9802 - acc: 0.7059 - val_loss: 0.8975 - val_acc: 0.7334\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9832 - acc: 0.7041 - val_loss: 0.8992 - val_acc: 0.7339\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.9789 - acc: 0.7069 - val_loss: 1.0266 - val_acc: 0.6939\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9824 - acc: 0.7031 - val_loss: 0.9956 - val_acc: 0.7022\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9794 - acc: 0.7054 - val_loss: 0.8791 - val_acc: 0.7382\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9718 - acc: 0.7093 - val_loss: 0.9558 - val_acc: 0.7112\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9772 - acc: 0.7061 - val_loss: 0.9093 - val_acc: 0.7290\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9802 - acc: 0.7039 - val_loss: 0.9944 - val_acc: 0.6966\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9747 - acc: 0.7104 - val_loss: 0.8662 - val_acc: 0.7443\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9746 - acc: 0.7092 - val_loss: 0.9237 - val_acc: 0.7285\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.9742 - acc: 0.7072 - val_loss: 0.8876 - val_acc: 0.7356\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9706 - acc: 0.7096 - val_loss: 1.0047 - val_acc: 0.7027\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.9720 - acc: 0.7094 - val_loss: 0.9110 - val_acc: 0.7305\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9711 - acc: 0.7093 - val_loss: 0.9286 - val_acc: 0.7234\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9756 - acc: 0.7067 - val_loss: 0.9046 - val_acc: 0.7275\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.9716 - acc: 0.7084 - val_loss: 0.9715 - val_acc: 0.7074\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.9703 - acc: 0.7119 - val_loss: 0.9502 - val_acc: 0.7154\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9695 - acc: 0.7088 - val_loss: 0.9313 - val_acc: 0.7200\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9692 - acc: 0.7106 - val_loss: 0.9443 - val_acc: 0.7117\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9730 - acc: 0.7105 - val_loss: 0.9478 - val_acc: 0.7170\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9699 - acc: 0.7097 - val_loss: 0.9468 - val_acc: 0.7134\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9726 - acc: 0.7088 - val_loss: 0.9451 - val_acc: 0.7177\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9672 - acc: 0.7111 - val_loss: 0.8830 - val_acc: 0.7397\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.9691 - acc: 0.7084 - val_loss: 0.9159 - val_acc: 0.7288\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9645 - acc: 0.7115 - val_loss: 0.8526 - val_acc: 0.7461\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9602 - acc: 0.7122 - val_loss: 0.9506 - val_acc: 0.7138\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9674 - acc: 0.7103 - val_loss: 0.8922 - val_acc: 0.7338\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9633 - acc: 0.7142 - val_loss: 0.8630 - val_acc: 0.7445\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9667 - acc: 0.7109 - val_loss: 0.9360 - val_acc: 0.7220\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9675 - acc: 0.7112 - val_loss: 0.8983 - val_acc: 0.7331\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9625 - acc: 0.7112 - val_loss: 0.9392 - val_acc: 0.7202\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9592 - acc: 0.7153 - val_loss: 0.9567 - val_acc: 0.7205\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9581 - acc: 0.7117 - val_loss: 0.9884 - val_acc: 0.7131\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9615 - acc: 0.7113 - val_loss: 0.8848 - val_acc: 0.7390\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.9564 - acc: 0.7111 - val_loss: 0.9495 - val_acc: 0.7133\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.9639 - acc: 0.7098 - val_loss: 0.8989 - val_acc: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bdf0eff48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1) #earlystop\n",
    "\n",
    "#開始訓練\n",
    "classifier.fit_generator(img_gen.flow(x_train, y_train, batch_size=100), steps_per_epoch=500,\n",
    "                        epochs=100, validation_data = (x_test, y_test), callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1704670e-03, 7.3058021e-05, 4.5072636e-01, 6.7761838e-02,\n",
       "        4.1899461e-01, 7.3583652e-03, 3.9801862e-02, 2.7033640e-03,\n",
       "        3.3141770e-03, 9.5944168e-05]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
